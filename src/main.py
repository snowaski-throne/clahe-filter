from js import ImageData, Object, slyApp
from pyodide.ffi import create_proxy
import numpy as np
import cv2


def dump(obj):
    for attr in dir(obj):
        print("obj.%s = %r" % (attr, getattr(obj, attr)))

def apply_image_processing(img_bgr, method='hist', clip_limit=40, use_lab=False):
    """Apply CLAHE or histogram equalization to a BGR image"""
    try:
        if method == 'clahe':
            if use_lab:
                # Convert to LAB color space
                lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
                # Apply CLAHE to L channel
                clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8,8))
                lab[:, :, 0] = clahe.apply(lab[:, :, 0])
                # Convert back to BGR
                return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            else:
                # Convert to grayscale, apply CLAHE, then back to BGR
                gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8,8))
                enhanced = clahe.apply(gray)
                return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
        
        elif method == 'hist':
            if use_lab:
                # Convert to LAB color space
                lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
                # Apply histogram equalization to L channel
                lab[:, :, 0] = cv2.equalizeHist(lab[:, :, 0])
                # Convert back to BGR
                return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
            else:
                # Convert to grayscale, apply histogram equalization, then back to BGR
                gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                enhanced = cv2.equalizeHist(gray)
                return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
        
        return img_bgr
    except Exception as e:
        print(f"Error in image processing: {e}")
        return img_bgr

def get_frame_np_processed(api, images_cache, video_id, frame_index, method='hist', clip_limit=40, use_lab=False):
    """Enhanced version of get_frame_np with CLAHE/histogram processing"""
    # Create unique keys for both original and processed frames
    original_key = "{}_{}".format(video_id, frame_index)
    processed_key = "{}_{}_{}_{}_{}".format(video_id, frame_index, method, clip_limit, use_lab)
    
    # Check if processed frame is already cached
    if processed_key in images_cache:
        return images_cache[processed_key]
    
    # Get original frame (using existing caching logic)
    if original_key not in images_cache:
        img_rgb = api.video.frame.download_np(video_id, frame_index)
        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
        images_cache[original_key] = img_bgr
    
    original_frame = images_cache[original_key]
    
    # Apply processing
    processed_frame = apply_image_processing(original_frame, method, clip_limit, use_lab)
    
    # Cache processed frame
    images_cache[processed_key] = processed_frame
    
    return processed_frame

def main(mode='process', method='hist'):
    try:
        # Safer access to Supervisely app components with fallbacks
        app = None
        store = None
        context = None
        state = None
        
        try:
            app = slyApp.app
            if hasattr(slyApp, 'store'):
                store = slyApp.store
                app = getattr(app, '$children')[0]
                context = app.context
                state = app.state
        except Exception as access_error:
            print(f"Warning: Limited access to Supervisely components: {access_error}")
            
        # Get current image/video ID
        current_image_id = None
        if context and hasattr(context, 'imageId'):
            current_image_id = context.imageId
        else:
            # Try alternative access methods
            try:
                if app and hasattr(app, 'context'):
                    current_image_id = app.context.imageId
            except:
                current_image_id = "unknown"
        
        print(f"Main called with mode={mode}, method={method}")
        print(f"Current imageId: {current_image_id}")
        
        # Real video processing approach using Supervisely API + OpenCV
        print("=== REAL VIDEO PROCESSING ===")
        
        # Get processing parameters from UI state (with fallbacks)
        clip_limit = 40
        use_lab = False
        
        if state:
            try:
                if hasattr(state, 'SliderAutoId6MqE3') and method == 'clahe':
                    clip_limit = state.SliderAutoId6MqE3.value
                if hasattr(state, 'labCheck'):
                    use_lab = state.labCheck
            except Exception as state_error:
                print(f"Warning: Could not access UI state: {state_error}")
        
        print(f"Processing parameters:")
        print(f"  Method: {method}")
        print(f"  Clip limit: {clip_limit}")
        print(f"  Use LAB color space: {use_lab}")
        
        # Extract video/frame information if available
        video_id = current_image_id
        frame_index = 0
        
        if store:
            try:
                current_frame = getattr(store.state.videos.all, str(current_image_id))
                
                if hasattr(current_frame, 'videoId'):
                    video_id = current_frame.videoId
                elif hasattr(current_frame, 'id'):
                    video_id = current_frame.id
                    
                if hasattr(current_frame, 'frameIndex'):
                    frame_index = current_frame.frameIndex
                elif hasattr(current_frame, 'index'):
                    frame_index = current_frame.index
                    
                print(f"Processing video_id: {video_id}, frame_index: {frame_index}")
            
            except Exception as e:
                print(f"Note: Using fallback frame info due to: {e}")
                print(f"Using fallback - video_id: {video_id}, frame_index: {frame_index}")
        else:
            print(f"Using minimal processing - video_id: {video_id}, frame_index: {frame_index}")
        
        print(f"Processing parameters:")
        print(f"  Method: {method}")
        print(f"  Clip limit: {clip_limit}")
        print(f"  Use LAB color space: {use_lab}")
        
        if mode == 'restore':
            print("üîÑ Restoring original image")
            restore_original_image()
            return
        
        # SIMPLE IMAGE PROCESSING APPROACH
        print("üéØ Processing current frame and displaying on canvas:")
        print(f"üîß Processing method: {method.upper()}")
        if method == 'clahe':
            print(f"‚öôÔ∏è CLAHE clip limit: {clip_limit}")
        print(f"üé® Color space: {'LAB' if use_lab else 'Grayscale ‚Üí BGR'}")
        
        # Process current frame and display on canvas
        process_and_display_image(video_id, frame_index, method, clip_limit, use_lab)

    except Exception as e:
        print(f"Error in main function: {str(e)}")
        import traceback
        traceback.print_exc()

def process_and_display_image(video_id, frame_index, method, clip_limit, use_lab):
    """Download current frame, process it with OpenCV, and display on canvas"""
    try:
        print("üñºÔ∏è Starting simple image processing...")
        
        # Step 1: Get current frame from Supervisely
        print("üì• Downloading current frame...")
        frame_image = get_current_frame(video_id, frame_index)
        if frame_image is None:
            print("‚ùå Could not get current frame")
            return False
        
        print(f"‚úÖ Downloaded frame: {frame_image.shape}")
        
        # Step 2: Process frame with OpenCV
        print(f"üîß Processing frame with {method.upper()}...")
        processed_image = apply_image_processing(frame_image, method, clip_limit, use_lab)
        if processed_image is None:
            print("‚ùå Failed to process frame")
            return False
        
        print(f"‚úÖ Processed frame: {processed_image.shape}")
        
        # Step 3: Display processed image on canvas
        print("üé® Displaying processed image on canvas...")
        success = display_image_on_canvas(processed_image)
        
        if success:
            print("üéâ Successfully displayed processed image!")
            return True
        else:
            print("‚ö†Ô∏è Image processed but canvas update failed")
            return False
        
    except Exception as e:
        print(f"Error in image processing pipeline: {e}")
        import traceback
        traceback.print_exc()
        return False

def get_current_frame(video_id, frame_index):
    """Get the current frame from Supervisely as a numpy array"""
    try:
        from js import slyApp
        print(f"üì• Getting frame {frame_index} from video {video_id}")
        
        # Try to get frame using Supervisely API
        if hasattr(slyApp, 'app') and slyApp.app:
            app = slyApp.app
            if hasattr(app, 'api'):
                api = app.api
                try:
                    # Download frame as RGB numpy array
                    img_rgb = api.video.frame.download_np(video_id, frame_index)
                    # Convert to BGR for OpenCV
                    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
                    print(f"‚úÖ Downloaded frame via API: {img_bgr.shape}")
                    return img_bgr
                except Exception as api_error:
                    print(f"API download failed: {api_error}")
        
        # Fallback: Try to get frame from store/cache
        if hasattr(slyApp, 'store') and slyApp.store:
            store = slyApp.store
            try:
                # Check if frame is cached
                cache_key = f"{video_id}_{frame_index}"
                if hasattr(store.state, 'imagesCache') and hasattr(store.state.imagesCache, cache_key):
                    cached_frame = getattr(store.state.imagesCache, cache_key)
                    print(f"‚úÖ Found cached frame: {cached_frame.shape}")
                    return cached_frame
            except Exception as cache_error:
                print(f"Cache access failed: {cache_error}")
        
        # Final fallback: Create a test image
        print("üì∏ Creating test image for processing demonstration...")
        test_image = create_test_image()
        return test_image
        
    except Exception as e:
        print(f"Error getting current frame: {e}")
        # Return test image as final fallback
        return create_test_image()

def create_test_image():
    """Create a test image for processing demonstration"""
    try:
        import numpy as np
        
        # Create a realistic test image with various brightness regions
        height, width = 480, 640
        test_img = np.zeros((height, width, 3), dtype=np.uint8)
        
        # Create gradient backgrounds
        for y in range(height):
            for x in range(width):
                test_img[y, x, 0] = int(50 + (x / width) * 150)  # Blue gradient
                test_img[y, x, 1] = int(30 + (y / height) * 120)  # Green gradient
                test_img[y, x, 2] = int(80 + ((x + y) / (width + height)) * 100)  # Red gradient
        
        # Add some dark and bright regions to test CLAHE/histogram
        test_img[100:200, 100:250] = test_img[100:200, 100:250] // 4  # Dark region
        test_img[250:350, 350:500] = np.minimum(test_img[250:350, 350:500] * 2, 255)  # Bright region
        
        # Add some texture
        noise = np.random.randint(-15, 15, (height, width, 3), dtype=np.int16)
        test_img = np.clip(test_img.astype(np.int16) + noise, 0, 255).astype(np.uint8)
        
        print(f"üì∏ Created test image: {width}x{height}")
        return test_img
        
    except Exception as e:
        print(f"Error creating test image: {e}")
        # Final fallback
        return np.full((480, 640, 3), 128, dtype=np.uint8)

def display_image_on_canvas(processed_image):
    """Display the processed image on Supervisely's canvas"""
    try:
        from js import document, ImageData
        
        print("üé® Searching for Supervisely canvas...")
        
        # Find the main canvas in Supervisely's video player
        canvas = None
        
        # Method 1: Look for the exact Supervisely canvas structure
        fullsize_containers = document.querySelectorAll('div.fullsize[data-v-4662ca9e]')
        if not fullsize_containers:
            fullsize_containers = document.querySelectorAll('div.fullsize')
        
        for container in fullsize_containers:
            potential_canvas = container.querySelector('canvas[style*="position: absolute"]')
            if potential_canvas:
                canvas = potential_canvas
                print(f"‚úÖ Found Supervisely canvas: {canvas.width}x{canvas.height}")
                break
        
        # Method 2: Look for any large canvas
        if not canvas:
            all_canvases = document.querySelectorAll('canvas')
            for c in all_canvases:
                if c.width >= 500 and c.height >= 300:
                    canvas = c
                    print(f"‚úÖ Found large canvas: {canvas.width}x{canvas.height}")
                    break
        
        if not canvas:
            print("‚ùå No suitable canvas found")
            return False
        
        # Get canvas context
        ctx = canvas.getContext('2d')
        if not ctx:
            print("‚ùå Could not get canvas context")
            return False
        
        # Prepare image data
        height, width, channels = processed_image.shape
        print(f"üìê Image dimensions: {width}x{height}x{channels}")
        print(f"üìê Canvas dimensions: {canvas.width}x{canvas.height}")
        
        # Convert BGR to RGB for display
        img_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)
        
        # Resize image to match canvas if needed
        if width != canvas.width or height != canvas.height:
            img_rgb = cv2.resize(img_rgb, (canvas.width, canvas.height))
            print(f"üìè Resized image to match canvas: {canvas.width}x{canvas.height}")
        
        # Convert to ImageData format for JavaScript
        # Flatten the array and convert to RGBA
        img_flat = img_rgb.flatten()
        img_rgba = []
        
        for i in range(0, len(img_flat), 3):
            img_rgba.extend([
                int(img_flat[i]),     # R
                int(img_flat[i+1]),   # G  
                int(img_flat[i+2]),   # B
                255                   # A (full opacity)
            ])
        
        # Create ImageData object
        image_data = ImageData.new(img_rgba, canvas.width, canvas.height)
        
        # Clear canvas and draw new image
        ctx.clearRect(0, 0, canvas.width, canvas.height)
        ctx.putImageData(image_data, 0, 0)
        
        print("‚úÖ Successfully displayed processed image on canvas!")
        return True
        
    except Exception as e:
        print(f"Error displaying image on canvas: {e}")
        import traceback
        traceback.print_exc()
        return False

def restore_original_image():
    """Restore the original image on canvas"""
    try:
        print("üîÑ Restoring original image...")
        from js import document
        
        # Find and clear any overlays or filters
        overlay_elements = document.querySelectorAll('[style*="position: absolute"][style*="z-index"]')
        removed = 0
        
        for element in overlay_elements:
            if 'video' in element.tagName.lower() or 'img' in element.tagName.lower():
                element.remove()
                removed += 1
        
        print(f"üóëÔ∏è Removed {removed} overlay elements")
        
        # Reset canvas if possible
        canvases = document.querySelectorAll('canvas')
        for canvas in canvases:
            if canvas.width >= 500 and canvas.height >= 300:
                ctx = canvas.getContext('2d')
                if ctx:
                    ctx.clearRect(0, 0, canvas.width, canvas.height)
                    print("üßπ Cleared main canvas")
        
        print("‚úÖ Original image restoration complete")
        return True
        
    except Exception as e:
        print(f"Error restoring original image: {e}")
        return False

main
